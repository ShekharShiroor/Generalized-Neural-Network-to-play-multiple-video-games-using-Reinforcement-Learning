{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries necessary for data preprocessing \n",
    "import gym\n",
    "from cv2 import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random weights array once to be used to bring the 'observation' to 1000/256/any number (has to be consistent) units.\n",
    "sizeOfArray = 256\n",
    "\n",
    "if os.path.exists('weights_'+str(sizeOfArray)+'.npy'):\n",
    "    array_weights_for_observation = np.load('weights_'+str(sizeOfArray)+'.npy')\n",
    "else:\n",
    "    array_weights_for_observation = np.random.rand(1,sizeOfArray)\n",
    "    np.save('weights_'+str(sizeOfArray)+'.npy',array_weights_for_observation)\n",
    "\n",
    "array_weights_for_observation = array_weights_for_observation.reshape(sizeOfArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_obs = []\n",
    "X_img = []\n",
    "Y = []\n",
    "initial_games = 1000  # Number of games to collect the data set. \n",
    "target_score = 1200  # minimum treshold score to save the game to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Carnival-ram-v0\"   #one example name of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_name = \"Boxing-ram-v0\"\n",
    "env = gym.make(env_name)\n",
    "for _ in tqdm(range(initial_games)):\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    X_obs = []\n",
    "    Y_temp = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        #time.sleep(0.05)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        \n",
    "        if len(observation) > sizeOfArray: # get all observation array to size of 1000/256/any unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation.append([0]*(sizeOfArray-(len(observation)%sizeOfArray)))\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "            \n",
    "        #print(action)\n",
    "        if prev_obs != []:\n",
    "            temp_Y = [0] * 10\n",
    "            temp_Y[action] = 1\n",
    "            Y_temp.append(temp_Y)\n",
    "            score += reward\n",
    "            X_obs.append(img)\n",
    "            X_obs.append(prev_obs)\n",
    "            #X.append(score)\n",
    "        prev_obs = list(observation)\n",
    "        \n",
    "        if done:\n",
    "            #print(score)\n",
    "            break\n",
    "    if score >= target_score:\n",
    "        X.append(X_obs)\n",
    "        Y.append(Y_temp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1684.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting the data in a convenient format for Neural Network to process later \n",
    "len(X)  \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X_final = []\n",
    "Y_final = []\n",
    "for i in tqdm(range(int(X.size))):\n",
    "    for j in range(len(X[i])):\n",
    "        X_final.append(X[i][j])\n",
    "        \n",
    "    for j in range(len(Y[i])):\n",
    "        Y_final.append(Y[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_final)\n",
    "Y = np.array(Y_final)\n",
    "X_final = []\n",
    "Y_final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(int(X.size/2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4733, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(env_name+'_X_10.npy',X)   # Save the dataset for the current game for reuse\n",
    "np.save(env_name+'_Y_10.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "np.save(env_name+'_X_10_Test.npy',X)\n",
    "np.save(env_name+'_Y_10_Test.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(env_name+'_X_10.npy')  # Load the saved dataset\n",
    "Y = np.load(env_name+'_Y_10.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(env_name+'_X.npy',X)\n",
    "np.save(env_name+'_Y.npy',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(env_name+'_X.npy')\n",
    "Y = np.load(env_name+'_Y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow and TFLearn libraries required to build, train and test the neural network.\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-1'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric can be set here.\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "train_X = X[:-2000]\n",
    "test_X = X[-2000:]\n",
    "train_Y = Y[:-2000]\n",
    "test_Y = Y[-2000:]\n",
    "\n",
    "X_1 = np.array([i[0] for i in train_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "X_2 = np.array([i[1] for i in train_X]).reshape(-1,len(X[0][1]))\n",
    "#X_3 = np.array([i[2] for i in train_X]).reshape(-1,1)\n",
    "\n",
    "test_X_1 = np.array([i[0] for i in test_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_X_2 = np.array([i[1] for i in test_X]).reshape(-1,len(X[0][1]))\n",
    "#test_X_3 = np.array([i[2] for i in test_X]).reshape(-1,1)\n",
    "\n",
    "model.fit({'input-1': X_1, 'input-2': X_2}, {'targets': train_Y}, n_epoch=8, validation_set=({'input-1': test_X_1, 'input-2': test_X_2}, {'targets': test_Y}), \n",
    "     show_metric=True, run_id=MODEL_NAME, batch_size = 16)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-2'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = tf.reshape(convnet, shape=[-1, 15, 2000])\n",
    "convnet =  tflearn.lstm(convnet, 1024, activation='relu', return_seq=True)\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 512, activation='relu', return_seq=True)\n",
    "\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 256, activation='relu')\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric can be set here\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "train_X = X[:-2000]\n",
    "test_X = X[-2000:]\n",
    "train_Y = Y[:-2000]\n",
    "test_Y = Y[-2000:]\n",
    "\n",
    "X_1 = np.array([i[0] for i in train_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "X_2 = np.array([i[1] for i in train_X]).reshape(-1,len(X[0][1]))\n",
    "#X_3 = np.array([i[2] for i in train_X]).reshape(-1,1)\n",
    "\n",
    "test_X_1 = np.array([i[0] for i in test_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_X_2 = np.array([i[1] for i in test_X]).reshape(-1,len(X[0][1]))\n",
    "#test_X_3 = np.array([i[2] for i in test_X]).reshape(-1,1)\n",
    "\n",
    "model.fit({'input-1': X_1, 'input-2': X_2}, {'targets': train_Y}, n_epoch=8, validation_set=({'input-1': test_X_1, 'input-2': test_X_2}, {'targets': test_Y}), \n",
    "     show_metric=True, run_id=MODEL_NAME, batch_size = 16)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 3\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-3'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2)\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "train_X = X[:-2000]\n",
    "test_X = X[-2000:]\n",
    "train_Y = Y[:-2000]\n",
    "test_Y = Y[-2000:]\n",
    "\n",
    "X_1 = np.array([i[0] for i in train_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "X_2 = np.array([i[1] for i in train_X]).reshape(-1,len(X[0][1]))\n",
    "#X_3 = np.array([i[2] for i in train_X]).reshape(-1,1)\n",
    "\n",
    "test_X_1 = np.array([i[0] for i in test_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_X_2 = np.array([i[1] for i in test_X]).reshape(-1,len(X[0][1]))\n",
    "#test_X_3 = np.array([i[2] for i in test_X]).reshape(-1,1)\n",
    "\n",
    "model.fit({'input-1': X_1, 'input-2': X_2}, {'targets': train_Y}, n_epoch=8, validation_set=({'input-1': test_X_1, 'input-2': test_X_2}, {'targets': test_Y}), \n",
    "     show_metric=True, run_id=MODEL_NAME, batch_size = 16)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-4'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric is set here\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "train_X = X[:-2000]\n",
    "test_X = X[-2000:]\n",
    "train_Y = Y[:-2000]\n",
    "test_Y = Y[-2000:]\n",
    "\n",
    "X_1 = np.array([i[0] for i in train_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "X_2 = np.array([i[1] for i in train_X]).reshape(-1,len(X[0][1]))\n",
    "#X_3 = np.array([i[2] for i in train_X]).reshape(-1,1)\n",
    "\n",
    "test_X_1 = np.array([i[0] for i in test_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_X_2 = np.array([i[1] for i in test_X]).reshape(-1,len(X[0][1]))\n",
    "#test_X_3 = np.array([i[2] for i in test_X]).reshape(-1,1)\n",
    "\n",
    "model.fit({'input-1': X_1, 'input-2': X_2}, {'targets': train_Y}, n_epoch=8, validation_set=({'input-1': test_X_1, 'input-2': test_X_2}, {'targets': test_Y}), \n",
    "     show_metric=True, run_id=MODEL_NAME, batch_size = 16)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-5'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = tf.reshape(convnet, shape=[-1, 16, 2])\n",
    "convnet =  tflearn.lstm(convnet, 1024, activation='relu', return_seq=True)\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 512, activation='relu', return_seq=True)\n",
    "\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 256, activation='relu')\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2)\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "train_X = X[:-2000]\n",
    "test_X = X[-2000:]\n",
    "train_Y = Y[:-2000]\n",
    "test_Y = Y[-2000:]\n",
    "\n",
    "X_1 = np.array([i[0] for i in train_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "X_2 = np.array([i[1] for i in train_X]).reshape(-1,len(X[0][1]))\n",
    "#X_3 = np.array([i[2] for i in train_X]).reshape(-1,1)\n",
    "\n",
    "test_X_1 = np.array([i[0] for i in test_X]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "test_X_2 = np.array([i[1] for i in test_X]).reshape(-1,len(X[0][1]))\n",
    "#test_X_3 = np.array([i[2] for i in test_X]).reshape(-1,1)\n",
    "\n",
    "model.fit({'input-1': X_1, 'input-2': X_2}, {'targets': train_Y}, n_epoch=8, validation_set=({'input-1': test_X_1, 'input-2': test_X_2}, {'targets': test_Y}), \n",
    "     show_metric=True, run_id=MODEL_NAME, batch_size = 16)\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Neural Network model on the gym env game in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-1'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric can be set here.\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "action = 0\n",
    "print(action)\n",
    "j=0\n",
    "for _ in range(10):  # Play for 10 turns for the respective game\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        if action > 1:\n",
    "            action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = observation.flatten()\n",
    "        \n",
    "        if len(observation) > sizeOfArray:     # get all observation array to size of 1000/256/required unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation = np.array(observation)\n",
    "                observation = np.append(observation,([0]*(sizeOfArray-(len(observation)%sizeOfArray))))\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "        \n",
    "        if prev_obs != []:\n",
    "            img = img.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "            observation_1 = np.array(prev_obs).reshape(-1,len(prev_obs))\n",
    "            score += reward\n",
    "            #score_1 = np.array(score).reshape(-1,1)\n",
    "            action = np.argmax(model.predict([img,observation_1]))\n",
    "            #action = int(action - random.randint(0,10))\n",
    "            #print(action)\n",
    "            #print(model.predict([img,observation_1]))\n",
    "        prev_obs = list(observation)\n",
    "        j+=1\n",
    "        if done:\n",
    "            print(score)\n",
    "            break\n",
    "            \n",
    "'''\n",
    "# Alternate Way to test the Model. Test the Neural Network on the saved testing dataset frames \n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    temp = np.argmax(model.predict([X[i][0].reshape(-1,IMG_SIZE,IMG_SIZE,3), np.array(X[i][1]).reshape(-1,len(X[i][1]))]))\n",
    "    if(temp == np.argmax(Y[i])):\n",
    "        count+=1\n",
    "\n",
    "print(\"Accuracy is \"+ str(float((float(count)/float(X.shape[0]))*100))+ \"%\")\n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-2'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = tf.reshape(convnet, shape=[-1, 15, 2000])\n",
    "convnet =  tflearn.lstm(convnet, 1024, activation='relu', return_seq=True)\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 512, activation='relu', return_seq=True)\n",
    "\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 256, activation='relu')\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric can be set here\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "env = gym.make(env_name)\n",
    "action = 0\n",
    "print(action)\n",
    "j=0\n",
    "for _ in range(10):  # Play for 10 turns for the respective game\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        if action > 1:\n",
    "            action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = observation.flatten()\n",
    "        \n",
    "        if len(observation) > sizeOfArray:     # get all observation array to size of 1000/256/required unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation = np.array(observation)\n",
    "                observation = np.append(observation,([0]*(sizeOfArray-(len(observation)%sizeOfArray))))\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "        \n",
    "        if prev_obs != []:\n",
    "            img = img.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "            observation_1 = np.array(prev_obs).reshape(-1,len(prev_obs))\n",
    "            score += reward\n",
    "            #score_1 = np.array(score).reshape(-1,1)\n",
    "            action = np.argmax(model.predict([img,observation_1]))\n",
    "            #action = int(action - random.randint(0,10))\n",
    "            #print(action)\n",
    "            #print(model.predict([img,observation_1]))\n",
    "        prev_obs = list(observation)\n",
    "        j+=1\n",
    "        if done:\n",
    "            print(score)\n",
    "            break\n",
    "            \n",
    "'''\n",
    "# Alternate Way to test the Model. Test the Neural Network on the saved testing dataset frames \n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    temp = np.argmax(model.predict([X[i][0].reshape(-1,IMG_SIZE,IMG_SIZE,3), np.array(X[i][1]).reshape(-1,len(X[i][1]))]))\n",
    "    if(temp == np.argmax(Y[i])):\n",
    "        count+=1\n",
    "\n",
    "print(\"Accuracy is \"+ str(float((float(count)/float(X.shape[0]))*100))+ \"%\")\n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 3\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-3'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2)\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "env = gym.make(env_name)\n",
    "action = 0\n",
    "print(action)\n",
    "j=0\n",
    "for _ in range(10):  # Play for 10 turns for the respective game\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        if action > 1:\n",
    "            action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = observation.flatten()\n",
    "        \n",
    "        if len(observation) > sizeOfArray:     # get all observation array to size of 1000/256/required unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation = np.array(observation)\n",
    "                observation = np.append(observation,([0]*(sizeOfArray-(len(observation)%sizeOfArray))))\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "        \n",
    "        if prev_obs != []:\n",
    "            img = img.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "            observation_1 = np.array(prev_obs).reshape(-1,len(prev_obs))\n",
    "            score += reward\n",
    "            #score_1 = np.array(score).reshape(-1,1)\n",
    "            action = np.argmax(model.predict([img,observation_1]))\n",
    "            #action = int(action - random.randint(0,10))\n",
    "            #print(action)\n",
    "            #print(model.predict([img,observation_1]))\n",
    "        prev_obs = list(observation)\n",
    "        j+=1\n",
    "        if done:\n",
    "            print(score)\n",
    "            break\n",
    "            \n",
    "'''\n",
    "# Alternate Way to test the Model. Test the Neural Network on the saved testing dataset frames \n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    temp = np.argmax(model.predict([X[i][0].reshape(-1,IMG_SIZE,IMG_SIZE,3), np.array(X[i][1]).reshape(-1,len(X[i][1]))]))\n",
    "    if(temp == np.argmax(Y[i])):\n",
    "        count+=1\n",
    "\n",
    "print(\"Accuracy is \"+ str(float((float(count)/float(X.shape[0]))*100))+ \"%\")\n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-4'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "\n",
    "\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2) # Top K metric is set here\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "env = gym.make(env_name)\n",
    "action = 0\n",
    "print(action)\n",
    "j=0\n",
    "for _ in range(10):  # Play for 10 turns for the respective game\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        if action > 1:\n",
    "            action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = observation.flatten()\n",
    "        \n",
    "        if len(observation) > sizeOfArray:     # get all observation array to size of 1000/256/required unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation = np.array(observation)\n",
    "                observation = np.append(observation,([0]*(sizeOfArray-(len(observation)%sizeOfArray))))\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "        \n",
    "        if prev_obs != []:\n",
    "            img = img.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "            observation_1 = np.array(prev_obs).reshape(-1,len(prev_obs))\n",
    "            score += reward\n",
    "            #score_1 = np.array(score).reshape(-1,1)\n",
    "            action = np.argmax(model.predict([img,observation_1]))\n",
    "            #action = int(action - random.randint(0,10))\n",
    "            #print(action)\n",
    "            #print(model.predict([img,observation_1]))\n",
    "        prev_obs = list(observation)\n",
    "        j+=1\n",
    "        if done:\n",
    "            print(score)\n",
    "            break\n",
    "\n",
    "'''\n",
    "# Alternate Way to test the Model. Test the Neural Network on the saved testing dataset frames \n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    temp = np.argmax(model.predict([X[i][0].reshape(-1,IMG_SIZE,IMG_SIZE,3), np.array(X[i][1]).reshape(-1,len(X[i][1]))]))\n",
    "    if(temp == np.argmax(Y[i])):\n",
    "        count+=1\n",
    "\n",
    "print(\"Accuracy is \"+ str(float((float(count)/float(X.shape[0]))*100))+ \"%\")\n",
    "print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'Neural_Network_Model-5'\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input-1')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = tf.reshape(convnet, shape=[-1, 16, 2])\n",
    "convnet =  tflearn.lstm(convnet, 1024, activation='relu', return_seq=True)\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 512, activation='relu', return_seq=True)\n",
    "\n",
    "\n",
    "convnet =  tflearn.lstm(convnet, 256, activation='relu')\n",
    "\n",
    "convnet = fully_connected(convnet, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "#Input 2 processing\n",
    "convnet1 = input_data(shape=[None, len(array_weights_for_observation)], name='input-2')\n",
    "\n",
    "convnet1 = tf.reshape(convnet1, shape=[-1, 64, 4])\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 256, activation='relu', return_seq=True)\n",
    "\n",
    "convnet1 =  tflearn.lstm(convnet1, 128, activation='relu')\n",
    "convnet_partial_merge = fully_connected(convnet1, 64, activation='relu')\n",
    "\n",
    "#Merge layer\n",
    "convnet_partial_merge = tflearn.layers.merge_ops.merge ([convnet,convnet_partial_merge], 'elemwise_mul', axis=1, name='Merge')\n",
    "convnet_partial_merge = dropout(convnet_partial_merge, 0.8)\n",
    "\n",
    "print(convnet_partial_merge)\n",
    "\n",
    "convnet = fully_connected(convnet_partial_merge, 64, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 32, activation='relu')\n",
    "print(convnet.shape)\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "top_k = tflearn.metrics.Top_k(2)\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets',metric=top_k)\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log_new')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "\n",
    "    \n",
    "env = gym.make(env_name)\n",
    "action = 0\n",
    "print(action)\n",
    "j=0\n",
    "for _ in range(10):  # Play for 10 turns for the respective game\n",
    "    env.reset()\n",
    "    score = 0\n",
    "    prev_obs = []\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(0.03)\n",
    "        img = env.render(mode = 'rgb_array')\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        if action > 1:\n",
    "            action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        observation = observation.flatten()\n",
    "        \n",
    "        if len(observation) > sizeOfArray:     # get all observation array to size of 1000/256/required unit before saving\n",
    "            if len(observation) % sizeOfArray == 0:\n",
    "                observation = np.array(observation)\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "            else:\n",
    "                observation = np.array(observation)\n",
    "                observation = np.append(observation,([0]*(sizeOfArray-(len(observation)%sizeOfArray))))\n",
    "                observation = observation.reshape(-1,int(observation.size/sizeOfArray)).mean(axis=1)\n",
    "                observation = np.convolve(np.array(observation),array_weights_for_observation,'same')\n",
    "                \n",
    "        else:\n",
    "            observation = np.array(observation)\n",
    "            #print(observation.shape)\n",
    "            #print(array_weights_for_observation.shape)\n",
    "            observation = np.convolve(observation,array_weights_for_observation,'same')\n",
    "        \n",
    "        if prev_obs != []:\n",
    "            img = img.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "            observation_1 = np.array(prev_obs).reshape(-1,len(prev_obs))\n",
    "            score += reward\n",
    "            #score_1 = np.array(score).reshape(-1,1)\n",
    "            action = np.argmax(model.predict([img,observation_1]))\n",
    "            #action = int(action - random.randint(0,10))\n",
    "            #print(action)\n",
    "            #print(model.predict([img,observation_1]))\n",
    "        prev_obs = list(observation)\n",
    "        j+=1\n",
    "        if done:\n",
    "            print(score)\n",
    "            break\n",
    "            \n",
    "'''\n",
    "# Alternate Way to test the Model. Test the Neural Network on the saved testing dataset frames \n",
    "\n",
    "count=0\n",
    "for i in tqdm(range(X.shape[0])):\n",
    "    temp = np.argmax(model.predict([X[i][0].reshape(-1,IMG_SIZE,IMG_SIZE,3), np.array(X[i][1]).reshape(-1,len(X[i][1]))]))\n",
    "    if(temp == np.argmax(Y[i])):\n",
    "        count+=1\n",
    "\n",
    "print(\"Accuracy is \"+ str(float((float(count)/float(X.shape[0]))*100))+ \"%\")\n",
    "print(count)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
